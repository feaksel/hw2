In this homework project I experimented with Decision tree implementations and its various configurations.
With this project I learned that small changes in parameters can change the performance of the model. Such as max depth of 2 making it underfit but 4 is pretty fit.
Another thing I noticed is there is a performance to readability/understandability trade off while shallow depths made sense and easily understood by human eye when depths got larger and therefore model better performing, Choices made by the algorithm became confusing to understand.
Lastly as expected some features are really important to outcome than others even some becoming non contributing.

I used python 3.9.0 for my codes and notebooks.
